{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "315cc968",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176392e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr_datasets.partitioner import IidPartitioner\n",
    "from torch.utils.data import DataLoader\n",
    "import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class ClinicPartitioner(IidPartitioner):\n",
    "    \"\"\"Partitioner for splitting MNIST into 5 centers.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(num_partitions=5)\n",
    "\n",
    "    def load_partition(self, partition_id: int) -> datasets.Dataset:\n",
    "        \"\"\"\n",
    "        Creates 5 partitions of the dataset:\n",
    "            1. 0's and 1's\n",
    "            2. 2's and 3's\n",
    "            3. 4's and 5's\n",
    "            4. 6's and 7's\n",
    "            5. 8's and 9's\n",
    "        \"\"\"\n",
    "\n",
    "        # Return the entire dataset if partition_id is -1\n",
    "        if (partition_id == -1):\n",
    "            return self.dataset\n",
    "\n",
    "        df = pd.DataFrame(\n",
    "            {\n",
    "                \"image\": [np.array(img) for img in self.dataset[\"image\"]],\n",
    "                \"label\": self.dataset[\"label\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        df1 = df[df[\"label\"].isin([0, 1])]\n",
    "        df2 = df[df[\"label\"].isin([2, 3])]\n",
    "        df3 = df[df[\"label\"].isin([4, 5])]\n",
    "        df4 = df[df[\"label\"].isin([6, 7])]\n",
    "        df5 = df[df[\"label\"].isin([8, 9])]\n",
    "\n",
    "        def convertPDtoDS(df):\n",
    "            return datasets.Dataset.from_dict({\n",
    "                \"image\": [Image.fromarray(np.array(img)) for img in df[\"image\"]],\n",
    "                \"label\": df[\"label\"],\n",
    "            })\n",
    "\n",
    "        splitDataset = [\n",
    "            convertPDtoDS(df1),\n",
    "            convertPDtoDS(df2),\n",
    "            convertPDtoDS(df3),\n",
    "            convertPDtoDS(df4),\n",
    "            convertPDtoDS(df5),\n",
    "        ]\n",
    "\n",
    "        return splitDataset[partition_id]\n",
    "\n",
    "\n",
    "trainPartitioner = None\n",
    "testPartitioner = None\n",
    "\n",
    "\n",
    "def load_data(partition_id: int, split: int):\n",
    "    \"\"\"Load partition MNIST data.\"\"\"\n",
    "    # Only initialize `FederatedDataset` once\n",
    "    global trainPartitioner, testPartitioner\n",
    "    if trainPartitioner is None or testPartitioner is None:\n",
    "        trainPartitioner = ClinicPartitioner()\n",
    "        testPartitioner = ClinicPartitioner()\n",
    "        ds = datasets.load_dataset(path=\"ylecun/mnist\")\n",
    "        ds = datasets.concatenate_datasets([ds[\"train\"], ds[\"test\"]])\n",
    "        trainPartitioner.dataset = datasets.concatenate_datasets([ds.shard(5, i) for i in list(filter(lambda x: x != split, range(5)))])\n",
    "        testPartitioner.dataset = ds.shard(5, split)\n",
    "    partition_train = trainPartitioner.load_partition(partition_id)\n",
    "    partition_test = testPartitioner.load_partition(partition_id)\n",
    "\n",
    "    def apply_transforms(batch):\n",
    "        \"\"\"Apply transforms to the partition from FederatedDataset.\"\"\"\n",
    "        batch[\"image\"] = [(np.array(img, dtype=np.float32) / 256).flatten() for img in batch[\"image\"]] # Transform images to float and normalize\n",
    "        return batch\n",
    "\n",
    "\n",
    "    partition_train = partition_train.with_transform(apply_transforms)\n",
    "    partition_test = partition_test.with_transform(apply_transforms)\n",
    "    trainloader = DataLoader(partition_train, batch_size=32, shuffle=True)\n",
    "    testloader = DataLoader(partition_test, batch_size=32)\n",
    "    return trainloader, testloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422a29b8",
   "metadata": {},
   "source": [
    "# Get model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81108535",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment3ERAGEM.task import get_net_train_test\n",
    "\n",
    "Net, _, train, test = get_net_train_test(ILVariant=\"Task\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1db86f",
   "metadata": {},
   "source": [
    "# Train and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a40808",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_global_fold = []\n",
    "accuracies_01_fold = []\n",
    "accuracies_23_fold = []\n",
    "accuracies_45_fold = []\n",
    "accuracies_67_fold = []\n",
    "accuracies_89_fold = []\n",
    "for i in range(5):\n",
    "    net = Net()\n",
    "\n",
    "    trainloader_global, testloader_global = load_data(-1, i)\n",
    "    _, testloader01 = load_data(0, i)\n",
    "    _, testloader23 = load_data(1, i)\n",
    "    _, testloader45 = load_data(2, i)\n",
    "    _, testloader67 = load_data(3, i)\n",
    "    _, testloader89 = load_data(4, i)\n",
    "    print(f\"Loaded data for fold {i}\")\n",
    "\n",
    "    accuracies_global  = []\n",
    "    accuracies_01 = []\n",
    "    accuracies_23 = []\n",
    "    accuracies_45 = []\n",
    "    accuracies_67 = []\n",
    "    accuracies_89 = []\n",
    "\n",
    "    # Get initial performance\n",
    "    loss, accuracy_global, _, _, _ = test(net, testloader_global, \"cpu\")\n",
    "    loss01, accuracy01, _, _, _ = test(net, testloader01, \"cpu\")\n",
    "    loss23, accuracy23, _, _, _ = test(net, testloader23, \"cpu\")\n",
    "    loss45, accuracy45, _, _, _ = test(net, testloader45, \"cpu\")\n",
    "    loss67, accuracy67, _, _, _ = test(net, testloader67, \"cpu\")\n",
    "    loss89, accuracy89, _, _, _ = test(net, testloader89, \"cpu\")\n",
    "    accuracies_global.append(accuracy_global)\n",
    "    accuracies_01.append(accuracy01)\n",
    "    accuracies_23.append(accuracy23)\n",
    "    accuracies_45.append(accuracy45)\n",
    "    accuracies_67.append(accuracy67)\n",
    "    accuracies_89.append(accuracy89)\n",
    "\n",
    "    epocs = 50\n",
    "    for i in range(epocs):\n",
    "        print(f\"Epoch {i+1}/{epocs}\")\n",
    "        # Train the model\n",
    "        train_loss = train(net, trainloader_global, None, \"cpu\")\n",
    "\n",
    "        loss, accuracy_global, _, _, _ = test(net, testloader_global, \"cpu\")\n",
    "        loss01, accuracy01, _, _, _ = test(net, testloader01, \"cpu\")\n",
    "        loss23, accuracy23, _, _, _ = test(net, testloader23, \"cpu\")\n",
    "        loss45, accuracy45, _, _, _ = test(net, testloader45, \"cpu\")\n",
    "        loss67, accuracy67, _, _, _ = test(net, testloader67, \"cpu\")\n",
    "        loss89, accuracy89, _, _, _ = test(net, testloader89, \"cpu\")\n",
    "        print(f\"Epoch {i+1}/{epocs}, train_loss: {train_loss:.4f}, test_accuracy: {accuracy_global:.4f}\")\n",
    "        accuracies_global.append(accuracy_global)\n",
    "        accuracies_01.append(accuracy01)\n",
    "        accuracies_23.append(accuracy23)\n",
    "        accuracies_45.append(accuracy45)\n",
    "        accuracies_67.append(accuracy67)\n",
    "        accuracies_89.append(accuracy89)\n",
    "    accuracies_global_fold.append(accuracies_global)\n",
    "    accuracies_01_fold.append(accuracies_01)\n",
    "    accuracies_23_fold.append(accuracies_23)\n",
    "    accuracies_45_fold.append(accuracies_45)\n",
    "    accuracies_67_fold.append(accuracies_67)\n",
    "    accuracies_89_fold.append(accuracies_89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468174c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_save = {\n",
    "    \"accuracies_global\": accuracies_global_fold,\n",
    "    \"accuracies_01\": accuracies_01_fold,\n",
    "    \"accuracies_23\": accuracies_23_fold,\n",
    "    \"accuracies_45\": accuracies_45_fold,\n",
    "    \"accuracies_67\": accuracies_67_fold,\n",
    "    \"accuracies_89\": accuracies_89_fold\n",
    "}\n",
    "\n",
    "import pickle\n",
    "with open(\"accuracies_ML_task.pkl\", \"wb\") as f:\n",
    "    pickle.dump(d_save, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fdc879",
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_font_size = 14\n",
    "title_font_size = 16\n",
    "fig_title_font_size = 18\n",
    "legend_font_size = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807cfabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the accuracies from the file\n",
    "d_load = None\n",
    "with open(\"accuracies_ML_task.pkl\", \"rb\") as f:\n",
    "    d_load = pickle.load(f)\n",
    "\n",
    "acc_global = np.array(d_load[\"accuracies_global\"])\n",
    "acc_01 = np.array(d_load[\"accuracies_01\"])\n",
    "acc_23 = np.array(d_load[\"accuracies_23\"])\n",
    "acc_45 = np.array(d_load[\"accuracies_45\"])\n",
    "acc_67 = np.array(d_load[\"accuracies_67\"])\n",
    "acc_89 = np.array(d_load[\"accuracies_89\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6d9d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std(acc):\n",
    "    \"\"\"Get mean and std of the accuracies.\"\"\"\n",
    "    return np.mean(acc, axis=0), np.std(acc, axis=0)\n",
    "\n",
    "mean_global, std_global = get_mean_std(acc_global)\n",
    "mean_01, std_01 = get_mean_std(acc_01)\n",
    "mean_23, std_23 = get_mean_std(acc_23)\n",
    "mean_45, std_45 = get_mean_std(acc_45)\n",
    "mean_67, std_67 = get_mean_std(acc_67)\n",
    "mean_89, std_89 = get_mean_std(acc_89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d651db3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_final_mean_std(mean, std, label):\n",
    "    \"\"\"Print the final mean and std of the accuracies.\"\"\"\n",
    "    print(\"acctstd{\" + f\"{mean:.3f}\" +\"}{\" + f\"{std:.3f}\" +\"}\")\n",
    "    # print(f\"{label} - Mean: {mean:.4f}, Std: {std:.4f}\")\n",
    "\n",
    "print_final_mean_std(mean_global[-1], std_global[-1], \"Global\")\n",
    "print_final_mean_std(mean_01[-1], std_01[-1], \"0's and 1's\")\n",
    "print_final_mean_std(mean_23[-1], std_23[-1], \"2's and 3's\")\n",
    "print_final_mean_std(mean_45[-1], std_45[-1], \"4's and 5's\")\n",
    "print_final_mean_std(mean_67[-1], std_67[-1], \"6's and 7's\")\n",
    "print_final_mean_std(mean_89[-1], std_89[-1], \"8's and 9's\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d538524",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Plot:\n",
    "    def __init__(self):\n",
    "        self.fig, self.ax = plt.subplots()\n",
    "\n",
    "    def plot_mean_std(self, mean_data: np.ndarray, std_data: np.ndarray, title: str = \"\", name: str = \"\", x_label: str = \"Rounds\", y_label: str = \"Metric\", show_end_value: bool = False, ylims = (0, 1)):\n",
    "            rounds = np.arange(len(mean_data))\n",
    "\n",
    "            self.ax.plot(rounds, mean_data, label=f\"{name}\")\n",
    "            self.ax.fill_between(\n",
    "                rounds,\n",
    "                mean_data - std_data,\n",
    "                mean_data + std_data,\n",
    "                alpha=0.1,\n",
    "                # label=f\"{name} (Standard Deviation)\",\n",
    "            )\n",
    "\n",
    "            self.ax.set_xlabel(x_label, fontsize=axis_font_size)\n",
    "            self.ax.set_ylabel(\"Accuracy\", fontsize=axis_font_size)\n",
    "            self.ax.set_title(title, fontsize=title_font_size)\n",
    "            self.ax.set_ylim(ylims)\n",
    "            self.ax.grid()\n",
    "            \n",
    "            # Show last value of mean_data on the plot\n",
    "            # if show_end_value:\n",
    "            #     self.ax.text(\n",
    "            #         rounds[-1] + 5,\n",
    "            #         mean_data[-1],\n",
    "            #         f\"{mean_data[-1]:.3f}\",\n",
    "            #         fontsize=10,\n",
    "            #         verticalalignment=\"bottom\",\n",
    "            #         horizontalalignment=\"right\",\n",
    "            #         color=\"black\",\n",
    "            #         bbox=dict(facecolor=\"white\", edgecolor=\"black\", boxstyle=\"round,pad=0.3\"),\n",
    "            #     )\n",
    "\n",
    "            self.ax.legend(fontsize=legend_font_size, loc=\"lower right\")             \n",
    "\n",
    "            return self.fig, self.ax\n",
    "\n",
    "p = Plot()\n",
    "\n",
    "fig, ax = p.plot_mean_std(mean_global, std_global, title=\"FTIL Global Accuracy\", show_end_value=True, ylims=(0.6, 1))\n",
    "\n",
    "fig.savefig(\"exp3_ML_global_accuracy_task.svg\", format=\"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f555e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Plot()\n",
    "\n",
    "p.plot_mean_std(mean_01, std_01, title=\"FTIL Client Accuracy\", name=\"Domain 01\")\n",
    "p.plot_mean_std(mean_23, std_23, title=\"FTIL Client Accuracy\", name=\"Domain 23\")\n",
    "p.plot_mean_std(mean_45, std_45, title=\"FTIL Client Accuracy\", name=\"Domain 45\")\n",
    "p.plot_mean_std(mean_67, std_67, title=\"FTIL Client Accuracy\", name=\"Domain 67\")\n",
    "fig, ax = p.plot_mean_std(mean_89, std_89, title=\"FTIL Client Accuracy\", name=\"Domain 89\", ylims=(0.6, 1))\n",
    "\n",
    "fig.savefig(\"exp3_ML_domain_accuracy_task.svg\", format=\"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b2746e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5f52e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689337b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "from typing import Literal\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7961a262",
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_font_size = 14\n",
    "title_font_size = 16\n",
    "fig_title_font_size = 18\n",
    "legend_font_size = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8628406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "folderStr = f\"{sys.path[-1]}/../../../../experiment1ResultsMLP/dataPercentage=10p_nets=Net1largelayer_learningRates=0.01_epochs=500/\"\n",
    "\n",
    "data = None\n",
    "with open(folderStr + \"accuracy_mean.txt\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(data)\n",
    "\n",
    "# Set limits on the y_axis\n",
    "plt.ylim(0, 1)\n",
    "data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dcc119",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLPMetric = Literal[\"accuracy\", \"precision\", \"recall\", \"f1\", \"test_loss\", \"train_loss\"]\n",
    "DataPercentage = Literal[\"10p\", \"50p\", \"100p\"]\n",
    "Nets = Literal[\"Net1largelayer\", \"Net1layer\", \"Net2layer\", \"Net3layer\"]\n",
    "LearningRate = Literal[\"0.01\", \"0.001\", \"0.0001\"]\n",
    "\n",
    "def get_MLP_run_metric(metric: MLPMetric, dataPercentage: DataPercentage, net: Nets, learningRate: LearningRate) -> tuple[list[float], list[float]]:\n",
    "    folderStr = f\"{sys.path[-1]}/../../../../experiment1ResultsMLP/dataPercentage={dataPercentage}_nets={net}_learningRates={learningRate}_epochs=500/\"\n",
    "\n",
    "    mean_data = None\n",
    "    with open(folderStr + f\"{metric}_mean.txt\", \"rb\") as f:\n",
    "        mean_data = pickle.load(f)\n",
    "\n",
    "    var_data = None\n",
    "    with open(folderStr + f\"{metric}_var.txt\", \"rb\") as f:\n",
    "        var_data = pickle.load(f)\n",
    "\n",
    "    return mean_data, var_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c838f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBMetric = Literal[\"accuracy\", \"precision\", \"recall\", \"f1\", \"auc\"]\n",
    "Etas = Literal[\"0.1\", \"0.2\"]\n",
    "Subsamples = Literal[\"0.6\", \"1\"]\n",
    "MaxDepths = Literal[\"8\", \"10\"]\n",
    "\n",
    "def get_XGB_run_metric(metric: XGBMetric, dataPercentage: DataPercentage, eta: Etas, max_depth: MaxDepths, subsample: Subsamples) -> tuple[list[float], list[float]]:\n",
    "    folderStr = f\"{sys.path[-1]}/../../../../experiment1ResultsXGB/dataPercentage={dataPercentage}_eta={eta}_max_depth={max_depth}_subsample={subsample}/\"\n",
    "\n",
    "    mean_data = None\n",
    "    with open(folderStr + f\"{metric}_mean.txt\", \"rb\") as f:\n",
    "        mean_data = pickle.load(f)\n",
    "\n",
    "    var_data = None\n",
    "    with open(folderStr + f\"{metric}_var.txt\", \"rb\") as f:\n",
    "        var_data = pickle.load(f)\n",
    "\n",
    "    return np.array(mean_data), np.array(var_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f86968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class plot:\n",
    "    def __init__(self, title: str, plot_dim: int = (1, 1)):\n",
    "        fig, ax = plt.subplots(nrows=plot_dim[0], ncols=plot_dim[1])\n",
    "        self.fig = fig\n",
    "        self.ax = [ax] if plot_dim == (1, 1) else ax\n",
    "        (\n",
    "            self.ax[0].set_title(title)\n",
    "            if plot_dim == (1, 1)\n",
    "            else [ax.set_title(title) for ax in self.ax.flatten()]\n",
    "        )\n",
    "        self.fig.set_size_inches(12, 8)\n",
    "        self.fig.subplots_adjust(hspace=0.3)\n",
    "\n",
    "    def get_fig_ax(self):\n",
    "        return self.fig, self.ax\n",
    "\n",
    "    def plot_mean_var(\n",
    "        self,\n",
    "        index: int,\n",
    "        name: str,\n",
    "        mean_data: np.ndarray,\n",
    "        var_data: np.ndarray,\n",
    "        xlabel: str,\n",
    "        ylabel: str,\n",
    "        title: str = None,\n",
    "        ylims: float = None,\n",
    "        xlims: float = None,\n",
    "        include_labels: bool = False,\n",
    "    ):\n",
    "\n",
    "        rounds = range(1, len(mean_data) + 1)\n",
    "\n",
    "        if include_labels:\n",
    "            self.ax[index].plot(rounds, mean_data, label=f\"{name} (Mean)\")\n",
    "        else:\n",
    "            self.ax[index].plot(rounds, mean_data)\n",
    "\n",
    "        self.ax[index].fill_between(\n",
    "            rounds,\n",
    "            mean_data - var_data,\n",
    "            mean_data + var_data,\n",
    "            alpha=0.1,\n",
    "            # label=f\"{name} (Standard Deviation)\",\n",
    "        )\n",
    "\n",
    "        self.ax[index].set_xlabel(xlabel, fontsize=axis_font_size)\n",
    "\n",
    "        self.ax[index].set_ylabel(ylabel, fontsize=axis_font_size)\n",
    "\n",
    "        self.ax[index].set_ylim(ylims if ylims else None)\n",
    "        self.ax[index].set_xlim(xlims if xlims else None)\n",
    "        if title:\n",
    "            self.ax[index].set_title(title, fontsize=title_font_size)\n",
    "\n",
    "        self.ax[index].grid(True)\n",
    "\n",
    "    def plot_max_line(self, index: int, name: str, values, c=\"r\", include_labels: bool = False):\n",
    "        max_value = max(values)\n",
    "        if include_labels:\n",
    "            self.ax[index].axhline(\n",
    "                y=max_value, color=c, linestyle=\"--\", label=f\"{name} (Max Value)\"\n",
    "            )\n",
    "        else:\n",
    "            self.ax[index].axhline(\n",
    "                y=max_value, color=c, linestyle=\"--\"\n",
    "            )\n",
    "\n",
    "    def save_as_svg(self, filename: str):\n",
    "        self.fig.savefig(filename, format=\"svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ae5428",
   "metadata": {},
   "outputs": [],
   "source": [
    "m, v = get_MLP_run_metric(\"accuracy\", \"10p\", \"Net1largelayer\", \"0.0001\")\n",
    "\n",
    "p = plot(title=\"MLP Accuracy\")\n",
    "\n",
    "p.plot_mean_var(0, \"MLP\", m, v, \"Epochs\", \"Accuracy\", ylims=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4aab5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "m, v = get_XGB_run_metric(\"accuracy\", \"10p\", \"0.1\", \"10\", \"0.5\")\n",
    "\n",
    "p = plot(title=\"XGB Accuracy\")\n",
    "\n",
    "p.plot_mean_var(0, \"XGB\", m, v, \"Epochs\", \"Accuracy\", ylims=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ac9a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = plot(title=\"MLP overfit accuracy\", plot_dim=(2, 2))\n",
    "\n",
    "network1 = \"Net1largelayer\"\n",
    "network2 = \"Net1layer\"\n",
    "network3 = \"Net2layer\"\n",
    "network4 = \"Net3layer\"\n",
    "\n",
    "lr = \"0.0001\"\n",
    "\n",
    "\n",
    "def plot_MLP_10_vs_100_accuracy(\n",
    "    network: str,\n",
    "    lr: str,\n",
    "    p: plot,\n",
    "    index,\n",
    "    include_max: bool = True,\n",
    "    x_lims: tuple = None,\n",
    "    y_lims: tuple = None,\n",
    "    add_name: str = \"\",\n",
    "    additional_title: str = \"\",\n",
    "    change_title: bool = True,\n",
    "    include_labels: bool = False,\n",
    "):\n",
    "    m_mlp10, sd_mlp10 = get_MLP_run_metric(\"accuracy\", \"10p\", network, lr)\n",
    "    p.plot_mean_var(\n",
    "        index,\n",
    "        \"10% Data\" + (f\" ({add_name})\" if add_name else \"\"),\n",
    "        m_mlp10,\n",
    "        sd_mlp10,\n",
    "        \"Epochs\",\n",
    "        \"Accuracy\",\n",
    "        ylims=(0, 1) if not y_lims else y_lims,\n",
    "        xlims=x_lims,\n",
    "        title=\"Validation Accuracy\" + additional_title,\n",
    "        include_labels=include_labels,\n",
    "    )\n",
    "    m_mlp100, sd_mlp100 = get_MLP_run_metric(\"accuracy\", \"100p\", network, lr)\n",
    "    p.plot_mean_var(\n",
    "        index,\n",
    "        \"100% Data\" + (f\" ({add_name})\" if add_name else \"\"),\n",
    "        m_mlp100,\n",
    "        sd_mlp100,\n",
    "        \"Epochs\",\n",
    "        \"Accuracy\",\n",
    "        ylims=(0, 1) if not y_lims else y_lims,\n",
    "        xlims=x_lims,\n",
    "        include_labels=include_labels,\n",
    "    )\n",
    "\n",
    "    if include_max:\n",
    "        p.plot_max_line(\n",
    "            index, \"10% Data\", m_mlp10, c=\"blue\", include_labels=include_labels\n",
    "        )\n",
    "        p.plot_max_line(\n",
    "            index, \"100% Data\", m_mlp100, c=\"orange\", include_labels=include_labels\n",
    "        )\n",
    "\n",
    "\n",
    "plot_MLP_10_vs_100_accuracy(\n",
    "    network1, lr, p, (0, 0), y_lims=(0.6, 0.9), include_labels=True, additional_title=\", MLP: 1 large layer\"\n",
    ")\n",
    "plot_MLP_10_vs_100_accuracy(network2, lr, p, (0, 1), y_lims=(0.6, 0.9), additional_title=\", MLP: 1 layer\")\n",
    "plot_MLP_10_vs_100_accuracy(network3, lr, p, (1, 0), y_lims=(0.6, 0.9), additional_title=\", MLP: 2 layers\")\n",
    "plot_MLP_10_vs_100_accuracy(network4, lr, p, (1, 1), y_lims=(0.6, 0.9), additional_title=\", MLP: 3 layers\")\n",
    "\n",
    "fig, ax = p.get_fig_ax()\n",
    "\n",
    "fig.legend(loc=\"lower center\", ncol=4, fontsize=legend_font_size)\n",
    "fig.subplots_adjust(bottom=0.14)\n",
    "\n",
    "p.save_as_svg(\"MLP_overfit_model.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fff1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p = plot(title=\"MLP overfit accuracy\", plot_dim=(1, 3))\n",
    "\n",
    "network1 = \"Net1layer\"\n",
    "\n",
    "ylims = (0.6, 0.9)\n",
    "plot_MLP_10_vs_100_accuracy(network1, \"0.01\", p, (0), y_lims=ylims, include_labels=True, additional_title=\", LR=0.01\")\n",
    "plot_MLP_10_vs_100_accuracy(network1, \"0.001\", p, (1), y_lims=ylims, additional_title=\", LR=0.001\")\n",
    "plot_MLP_10_vs_100_accuracy(network1, \"0.0001\", p, (2), y_lims=ylims, additional_title=\", LR=0.0001\")\n",
    "\n",
    "    \n",
    "fig, ax = p.get_fig_ax()\n",
    "\n",
    "fig.legend(loc=\"lower center\", ncol=4, fontsize=legend_font_size)\n",
    "\n",
    "fig.set_size_inches(16, 4)\n",
    "# Add space between subplots and legend\n",
    "fig.subplots_adjust(bottom=0.26)\n",
    "\n",
    "p.save_as_svg(\"MLP_overfit_lr.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0e6b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = plot(title=\"MLP overfit loss\")\n",
    "\n",
    "network = \"Net1largelayer\"\n",
    "\n",
    "# Plot MLP\n",
    "m_mlp10train, sd_mlp10train = get_MLP_run_metric(\"train_loss\", \"10p\", network, \"0.0001\")\n",
    "p.plot_mean_var(0, \"MLP 10% train\", m_mlp10train, 0, \"Epochs\", \"Loss\")\n",
    "m_mlp10test, sd_mlp10test = get_MLP_run_metric(\"test_loss\", \"10p\", network, \"0.0001\")\n",
    "p.plot_mean_var(0, \"MLP 10% test\", m_mlp10test, 0, \"Epochs\", \"Loss\")\n",
    "\n",
    "m_mlp100train, sd_mlp100train = get_MLP_run_metric(\"train_loss\", \"100p\", network, \"0.0001\")\n",
    "p.plot_mean_var(0, \"MLP 100% train\", m_mlp100train, 0, \"Epochs\", \"Loss\")\n",
    "m_mlp100test, sd_mlp100test = get_MLP_run_metric(\"test_loss\", \"100p\", network, \"0.0001\")\n",
    "p.plot_mean_var(0, \"MLP 100% test\", m_mlp100test, 0, \"Epochs\", \"Loss\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e89741",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = plot(title=\"XGB overfit accuracy\", plot_dim=(2, 2))\n",
    "\n",
    "\n",
    "def plot_XGB_10_vs_100_accuracy(max_depth: str, eta: str, p: plot, index, ylims: tuple = (0, 1), include_labels: bool = False):\n",
    "    m_xgb10, sd_xgb10 = get_XGB_run_metric(\"accuracy\", \"10p\", eta, max_depth, \"1\")\n",
    "    p.plot_mean_var(index, \"10% Data\", m_xgb10, sd_xgb10, \"Boost rounds\", \"Accuracy\", ylims=ylims, title=f\"XGB overfit accuracy\\n Max_depth={max_depth}, Eta={eta}\", include_labels=include_labels)\n",
    "    m_xgb100, sd_xgb100 = get_XGB_run_metric(\"accuracy\", \"100p\", eta, max_depth, \"1\")\n",
    "    p.plot_mean_var(index, \"100% Data\", m_xgb100, sd_xgb100, \"Boost rounds\", \"Accuracy\", ylims=ylims, include_labels=include_labels)\n",
    "\n",
    "\n",
    "    p.plot_max_line(index, \"10% Data\", m_xgb10, c=\"blue\", include_labels=include_labels)\n",
    "    p.plot_max_line(index, \"100% Data\", m_xgb100, c=\"orange\", include_labels=include_labels)\n",
    "\n",
    "    fig, ax = p.get_fig_ax()\n",
    "    fig.legend(loc=\"lower center\", ncol=4)\n",
    "    fig.subplots_adjust(bottom=0.12, hspace=0.5)\n",
    "\n",
    "ylims = (0.6, 0.9)\n",
    "\n",
    "plot_XGB_10_vs_100_accuracy(\"10\", \"0.1\", p, (0, 0), ylims=ylims, include_labels=True)\n",
    "plot_XGB_10_vs_100_accuracy(\"2\", \"0.1\", p, (0, 1), ylims=ylims)\n",
    "plot_XGB_10_vs_100_accuracy(\"10\", \"0.01\", p, (1, 0), ylims=ylims)\n",
    "plot_XGB_10_vs_100_accuracy(\"2\", \"0.01\", p, (1, 1), ylims=ylims)\n",
    "\n",
    "p.save_as_svg(\"XGB_overfit_accuracy.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7103ce14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
	"cells": [
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Load data"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"import sys\n",
				"sys.path.append('../flwrapp')"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"import datasets\n",
				"import pandas as pd\n",
				"import numpy as np\n",
				"import torch\n",
				"from torch.utils.data import DataLoader\n",
				"from dentalData.Pipelines import entire_data_processing_pipeline"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"ds = entire_data_processing_pipeline(sys.path[-1])"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"X, y = np.array(ds['features']), np.array(ds['labels'])\n",
				"\n",
				"# Convert labels to floats instead of int64\n",
				"X = np.array(X, dtype=float)\n",
				"y = np.array(y, dtype=float)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"def kFoldCrossValidationSplit(X, y, k = 5):\n",
				"    # TODO: Maybe add shuffling before splitting\n",
				"    segmentSize = X.shape[0] // k\n",
				"    segmentations = []\n",
				"    for i in range(k):\n",
				"        start = i * segmentSize\n",
				"        end = (i+1) * segmentSize\n",
				"        segmentation = {\n",
				"            \"X_train\": np.concatenate([X[:start, :], X[end:, :]]),\n",
				"            \"y_train\": np.concatenate([y[:start], y[end:]]),\n",
				"            \"X_test\": X[start:end],\n",
				"            \"y_test\": y[start:end],\n",
				"        }\n",
				"        segmentations.append(segmentation)\n",
				"    return segmentations\n",
				"        \n",
				"# Set k for the fold crossvalidation\n",
				"\n",
				"k = 5\n",
				"\n",
				"segmentations = kFoldCrossValidationSplit(X, y, k)\n",
				"\n",
				"segmentations[0][\"y_train\"].shape"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"def createSubTrainsets(segmentations: list):\n",
				"    splitSegmentations = []\n",
				"    for segmentation in segmentations:\n",
				"        train_len = segmentation[\"X_train\"].shape[0]\n",
				"        splitSegmentation = {\n",
				"            \"X_train_10p\": segmentation[\"X_train\"][:int(0.1*train_len)],\n",
				"            \"y_train_10p\": segmentation[\"y_train\"][:int(0.1*train_len)],\n",
				"            \"X_train_50p\": segmentation[\"X_train\"][:int(0.5*train_len)],\n",
				"            \"y_train_50p\": segmentation[\"y_train\"][:int(0.5*train_len)],\n",
				"            \"X_train_100p\": segmentation[\"X_train\"],\n",
				"            \"y_train_100p\": segmentation[\"y_train\"],\n",
				"            \"X_test_total\": segmentation[\"X_test\"],\n",
				"            \"y_test_total\": segmentation[\"y_test\"],\n",
				"        }\n",
				"        splitSegmentations.append(splitSegmentation)\n",
				"    return splitSegmentations\n",
				"\n",
				"splitSegmentations = createSubTrainsets(segmentations)\n",
				"\n",
				"splitSegmentations[0]['X_train_10p'].shape, np.mean(splitSegmentations[0]['y_train_100p'])"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Define dmatrix for XGBoost"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"import xgboost as xgb\n",
				"\n",
				"def convertToDMatrix(segmentation):\n",
				"    dmatrix_train_10p = xgb.DMatrix(segmentation[\"X_train_10p\"], label=segmentation[\"y_train_10p\"], enable_categorical=True)\n",
				"    dmatrix_train_50p = xgb.DMatrix(segmentation[\"X_train_50p\"], label=segmentation[\"y_train_50p\"], enable_categorical=True)\n",
				"    dmatrix_train_100p = xgb.DMatrix(segmentation[\"X_train_100p\"], label=segmentation[\"y_train_100p\"], enable_categorical=True)\n",
				"\n",
				"    dmatrix_test = xgb.DMatrix(segmentation[\"X_test_total\"], label=segmentation[\"y_test_total\"], enable_categorical=True)\n",
				"    \n",
				"    return {\n",
				"        \"dmatrix_train_10p\": dmatrix_train_10p,\n",
				"        \"dmatrix_train_50p\": dmatrix_train_50p,\n",
				"        \"dmatrix_train_100p\": dmatrix_train_100p,\n",
				"        \"dmatrix_test\": dmatrix_test\n",
				"    }\n",
				"\n",
				"dmatrixSegmentations = list(map(lambda x: convertToDMatrix(x), splitSegmentations))\n",
				"\n",
				"dmatrixSegmentations"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"def createAndTrainModel(dmatrix_train, test_dmatrices, params, num_boost_round=50):\n",
				"    bst = xgb.train(\n",
				"        params,\n",
				"        dmatrix_train,\n",
				"        num_boost_round=1\n",
				"    )\n",
				"    evals = [[bst.eval(dmatrix_test, \"Test\", 0) for dmatrix_test in test_dmatrices.values()]]\n",
				"    for i in range(1, num_boost_round):\n",
				"        bst.update(dmatrix_train, i)\n",
				"        evals.append([bst.eval(dmatrix_test, \"Test\", i) for dmatrix_test in test_dmatrices.values()])\n",
				"    return bst, evals"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"params = {\n",
				"    \"objective\": \"binary:logistic\",\n",
				"    \"eta\": 0.1, \n",
				"    \"max_depth\": 8,\n",
				"    \"eval_metric\":[\"error\"],\n",
				"    \"nthread\": 16,\n",
				"    \"num_parallel_tree\": 1,\n",
				"    \"subsample\": 1,\n",
				"    \"tree_method\": \"hist\"\n",
				"}\n",
				"\n",
				"def trainModels(dmatrices, params):\n",
				"    # Create dictionary of test matrices\n",
				"    test_dmatrices = {\n",
				"        \"Global\": dmatrices['dmatrix_test'],\n",
				"    }\n",
				"    bst_10p, evals_10p = createAndTrainModel(dmatrices['dmatrix_train_10p'], test_dmatrices, params)\n",
				"    bst_50p, evals_50p = createAndTrainModel(dmatrices['dmatrix_train_50p'], test_dmatrices, params)\n",
				"    bst_100p, evals_100p = createAndTrainModel(dmatrices['dmatrix_train_100p'], test_dmatrices, params)\n",
				"    return {\n",
				"        \"bst_10p\": bst_10p,\n",
				"        \"evals_10p\": evals_10p,\n",
				"        \"bst_50p\": bst_50p,\n",
				"        \"evals_50p\": evals_50p,\n",
				"        \"bst_100p\": bst_100p,\n",
				"        \"evals_100p\": evals_100p,\n",
				"    }\n",
				"\n",
				"segmentationsResults = list(map(lambda x: trainModels(x, params), dmatrixSegmentations))"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Plot results from 10%-train"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"import matplotlib.pyplot as plt\n",
				"\n",
				"def getValuesFromEvals(evals):\n",
				"    values = np.array([[float(inner_eval.split(\":\")[1]) for inner_eval in inner_evals] for inner_evals in evals])\n",
				"    # Put values into a dictionary\n",
				"    return values[:, 0]"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"eval_values_10p = list(map(lambda x: getValuesFromEvals(x['evals_10p']), segmentationsResults))\n",
				"\n",
				"eval_values_10pMEAN = np.mean(np.array(eval_values_10p), axis=0)\n",
				"\n",
				"# Plot test accuracy\n",
				"accuracy = 1 - np.array(eval_values_10pMEAN)\n",
				"print(f\"End of training 10% accuracy: {accuracy[-1]}\")\n",
				"plt.plot(accuracy, label=f'10% Test Accuracy')\n",
				"plt.ylabel('Accuracy')\n",
				"plt.xlabel('Epochs')\n",
				"plt.grid(True)\n",
				"\n",
				"# Set y-axis limits\n",
				"plt.ylim(0, 1)\n",
				"\n",
				"plt.legend()"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### Confusion matrix"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Make a confusion matrix for the test set\n",
				"from sklearn.metrics import confusion_matrix\n",
				"import seaborn as sns\n",
				"\n",
				"def plot_confusion_matrix(y_true, y_pred, title='Confusion Matrix', labels=None):\n",
				"    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
				"    cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
				"    plt.figure(figsize=(8, 6))\n",
				"    sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
				"    plt.title(title)\n",
				"    plt.xlabel('Predicted')\n",
				"    plt.ylabel('Known to be true')\n",
				"    plt.show()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"plot_confusion_matrix(y_test_total, bst_10p.predict(dmatrix_test) >= 0.5, title='Confusion Matrix for Test Set', labels=[0, 1])"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Plot results from 50%-train"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"eval_values_50p = list(map(lambda x: getValuesFromEvals(x['evals_50p']), segmentationsResults))\n",
				"\n",
				"eval_values_50pMEAN = np.mean(np.array(eval_values_50p), axis=0)\n",
				"\n",
				"# Plot test accuracy\n",
				"accuracy = 1 - np.array(eval_values_50pMEAN)\n",
				"print(f\"End of training 50% accuracy: {accuracy[-1]}\")\n",
				"plt.plot(accuracy, label=f'50% Test Accuracy')\n",
				"plt.ylabel('Accuracy')\n",
				"plt.xlabel('Epochs')\n",
				"plt.grid(True)\n",
				"\n",
				"# Set y-axis limits\n",
				"plt.ylim(0, 1)\n",
				"\n",
				"plt.legend()"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### Confusion matrix"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"plot_confusion_matrix(y_test_total, bst_50p.predict(dmatrix_test) >= 0.5, title='Confusion Matrix for Test Set', labels=[0, 1])"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Plot results from 100%-train"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"eval_values_100p = list(map(lambda x: getValuesFromEvals(x['evals_100p']), segmentationsResults))\n",
				"\n",
				"eval_values_100pMEAN = np.mean(np.array(eval_values_100p), axis=0)\n",
				"\n",
				"# Plot test accuracy\n",
				"accuracy = 1 - np.array(eval_values_100pMEAN)\n",
				"print(f\"End of training 100% accuracy: {accuracy[-1]}\")\n",
				"plt.plot(accuracy, label=f'100% Test Accuracy')\n",
				"plt.ylabel('Accuracy')\n",
				"plt.xlabel('Epochs')\n",
				"plt.grid(True)\n",
				"\n",
				"# Set y-axis limits\n",
				"plt.ylim(0, 1)\n",
				"\n",
				"plt.legend()"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### Confusion matrix"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"plot_confusion_matrix(y_test_total, bst_100p.predict(dmatrix_test) >= 0.5, title='Confusion Matrix for Test Set', labels=[0, 1])"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Plot of all accuracies"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Plot test accuracy\n",
				"accuracy_100p = 1 - np.array(eval_values_100pMEAN)\n",
				"accuracy_50p = 1 - np.array(eval_values_50pMEAN)\n",
				"accuracy_10p = 1 - np.array(eval_values_10pMEAN)\n",
				"print(f\"End of training 100% accuracy: {accuracy_100p[-1]}\")\n",
				"print(f\"End of training 50% accuracy: {accuracy_50p[-1]}\")\n",
				"print(f\"End of training 10% accuracy: {accuracy_10p[-1]}\")\n",
				"plt.plot(accuracy_100p, label=f'100% Test Accuracy')\n",
				"plt.plot(accuracy_50p, label=f'50% Test Accuracy')\n",
				"plt.plot(accuracy_10p, label=f'10% Test Accuracy')\n",
				"plt.ylabel('Accuracy')\n",
				"plt.xlabel('Epochs')\n",
				"plt.grid(True)\n",
				"\n",
				"# Set y-axis limits\n",
				"plt.ylim(0, 1)\n",
				"\n",
				"plt.legend()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": []
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": ".venv",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.11.9"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 2
}

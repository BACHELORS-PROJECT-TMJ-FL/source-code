{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../flwrapp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from dentalData.Pipelines import entire_data_processing_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = entire_data_processing_pipeline(sys.path[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = np.array(ds['features']), np.array(ds['labels'])\n",
    "\n",
    "X = np.array(X, dtype=float)\n",
    "y = np.array(y, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kFoldCrossValidationSplit(X, y, k = 5):\n",
    "    # TODO: Maybe add shuffling before splitting\n",
    "    segmentSize = X.shape[0] // k\n",
    "    segmentations = []\n",
    "    for i in range(k):\n",
    "        start = i * segmentSize\n",
    "        end = (i+1) * segmentSize\n",
    "        segmentation = {\n",
    "            \"X_train\": np.concatenate([X[:start, :], X[end:, :]]),\n",
    "            \"y_train\": np.concatenate([y[:start], y[end:]]),\n",
    "            \"X_test\": X[start:end],\n",
    "            \"y_test\": y[start:end],\n",
    "        }\n",
    "        segmentations.append(segmentation)\n",
    "    return segmentations\n",
    "        \n",
    "# Set k for the fold crossvalidation\n",
    "\n",
    "k = 5\n",
    "\n",
    "segmentations = kFoldCrossValidationSplit(X, y, k)\n",
    "\n",
    "segmentations[0][\"y_train\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSubTrainsets(segmentations: list):\n",
    "    splitSegmentations = []\n",
    "    for segmentation in segmentations:\n",
    "        train_len = segmentation[\"X_train\"].shape[0]\n",
    "        splitSegmentation = {\n",
    "            \"X_train_10p\": segmentation[\"X_train\"][:int(0.1*train_len)],\n",
    "            \"y_train_10p\": segmentation[\"y_train\"][:int(0.1*train_len)],\n",
    "            \"X_train_50p\": segmentation[\"X_train\"][:int(0.5*train_len)],\n",
    "            \"y_train_50p\": segmentation[\"y_train\"][:int(0.5*train_len)],\n",
    "            \"X_train_100p\": segmentation[\"X_train\"],\n",
    "            \"y_train_100p\": segmentation[\"y_train\"],\n",
    "            \"X_test_total\": segmentation[\"X_test\"],\n",
    "            \"y_test_total\": segmentation[\"y_test\"],\n",
    "        }\n",
    "        splitSegmentations.append(splitSegmentation)\n",
    "    return splitSegmentations\n",
    "\n",
    "splitSegmentations = createSubTrainsets(segmentations)\n",
    "\n",
    "splitSegmentations[0]['X_train_10p'].shape, np.mean(splitSegmentations[0]['y_train_100p'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for creating dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToDataloaders(trainSets, testSets):\n",
    "    # Define collate function for making list into stacked pytorch tensor\n",
    "    def collate_fn(batch):\n",
    "        features = torch.tensor([item['features'] for item in batch])\n",
    "        labels = torch.tensor([item['labels'] for item in batch])\n",
    "        return {'features': features, 'labels': labels}\n",
    "\n",
    "    trainloaders = []\n",
    "    for trainset in trainSets:\n",
    "        trainloaders.append(DataLoader(trainset, batch_size=32, shuffle=True, collate_fn=collate_fn))\n",
    "\n",
    "    testloaders = []\n",
    "    for testset in testSets:\n",
    "        testloaders.append(DataLoader(testset, batch_size=32, shuffle=True, collate_fn=collate_fn))\n",
    "    return trainloaders, testloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataLoader(segmentation):\n",
    "    trainsets = [\n",
    "        datasets.Dataset.from_dict(\n",
    "            {\n",
    "                \"features\": segmentation[\"X_train_10p\"],\n",
    "                \"labels\": segmentation[\"y_train_10p\"],\n",
    "            }\n",
    "        ),\n",
    "        datasets.Dataset.from_dict(\n",
    "            {\n",
    "                \"features\": segmentation[\"X_train_50p\"],\n",
    "                \"labels\": segmentation[\"y_train_50p\"],\n",
    "            }\n",
    "        ),\n",
    "        datasets.Dataset.from_dict(\n",
    "            {\n",
    "                \"features\": segmentation[\"X_train_100p\"],\n",
    "                \"labels\": segmentation[\"y_train_100p\"],\n",
    "            }\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    testSets = [\n",
    "        datasets.Dataset.from_dict(\n",
    "            {\"features\": segmentation[\"X_test_total\"], \"labels\": segmentation[\"y_test_total\"]}\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    trainloaders, testloaders = convertToDataloaders(trainsets, testSets)\n",
    "    trainloader10p = trainloaders[0]\n",
    "    trainloader50p = trainloaders[1]\n",
    "    trainloader100p = trainloaders[2]\n",
    "    testloader = testloaders[0]\n",
    "\n",
    "    return {\n",
    "        \"train_10p\": trainloader10p,\n",
    "        \"train_50p\": trainloader50p,\n",
    "        \"train_100p\": trainloader100p,\n",
    "        \"test\": testloader,\n",
    "    }\n",
    "\n",
    "dataloaderSegmentations = list(map(lambda x: createDataLoader(x), splitSegmentations))\n",
    "\n",
    "dataloaderSegmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define MLP to train and classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class Net(nn.Module):   \n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(115, 40)\n",
    "        self.fc2 = nn.Linear(40, 24)\n",
    "        self.fc3 = nn.Linear(24, 6)\n",
    "        self.fc4 = nn.Linear(6, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc3(x) \n",
    "        x = torch.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        x = torch.sigmoid(x)\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, trainloader, lr, device):\n",
    "    \"\"\"Train the net on the training set.\"\"\"\n",
    "    net.to(device)\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    \n",
    "    net.train()\n",
    "    epoch_loss = 0.0\n",
    "    for batch in trainloader:\n",
    "        data, targets = batch['features'], batch['labels']\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(data)[:, 0]\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(trainloader)\n",
    "    \n",
    "def test(net, testloader, device):\n",
    "    \"\"\"Validate the net on the test set.\"\"\"\n",
    "    net.to(device)\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    correct, loss = 0, 0.0 \n",
    "    with torch.no_grad():\n",
    "        for batch in testloader:\n",
    "            data = batch[\"features\"]\n",
    "            labels = batch[\"labels\"]\n",
    "            outputs = net(data.to(device))[:, 0]\n",
    "            loss += criterion(outputs, labels.to(device)).item()\n",
    "            correct += (outputs.data >= 0.5).eq(labels.to(device)).sum().item()\n",
    "    accuracy = correct / len(testloader.dataset)\n",
    "    loss = loss / len(testloader)\n",
    "    \n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAndEvaluateNetwork(net, epochs, trainloader, testloaders, lr, device):\n",
    "    trainloss = []\n",
    "    testloss = {'global': []}\n",
    "    testaccuracy = {'global': []}\n",
    "    \n",
    "    for key, tl in testloaders.items():\n",
    "        # Get initial loss and accuracy on all test sets\n",
    "        initTestLoss, initAccuracy = test(net, tl, device)\n",
    "        print(f\"Initial {key} - Test Loss: {initTestLoss}, Accuracy: {initAccuracy}\")\n",
    "        testloss[key].append(initTestLoss)\n",
    "        testaccuracy[key].append(initAccuracy)\n",
    "    \n",
    "    # Run thrugh the given amount of epochs\n",
    "    for epoch in range(epochs):\n",
    "        trainingLoss = train(net, trainloader, lr, device)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Trainloss: {trainingLoss:.4f}\")\n",
    "        trainloss.append(trainingLoss)\n",
    "        \n",
    "        # Evaluate the updated model on the test sets\n",
    "        for key, tl in testloaders.items():\n",
    "            # Get loss and accuracy on all test sets\n",
    "            testLoss, accuracy = test(net, tl, device)\n",
    "            print(f\"{key} - Test Loss: {testLoss}, Accuracy: {accuracy}\")\n",
    "            testloss[key].append(testLoss)\n",
    "            testaccuracy[key].append(accuracy)\n",
    "    \n",
    "    return trainloss, testloss, testaccuracy    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1 tests on ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for every experiment\n",
    "lr = 0.0001\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "epochs = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a network for each segmentation, and take the mean of the metrics\n",
    "trainloss10pLIST = []\n",
    "testloss10pLIST = []\n",
    "testaccuracy10pLIST = []\n",
    "for segmentation in dataloaderSegmentations:\n",
    "    net = Net()\n",
    "\n",
    "    trainloss10p, testloss10p, testaccuracy10p = trainAndEvaluateNetwork(net, epochs, segmentation['train_10p'], {\"global\": segmentation['test']}, lr, device)\n",
    "    trainloss10pLIST.append(trainloss10p)\n",
    "    testloss10pLIST.append(testloss10p)\n",
    "    testaccuracy10pLIST.append(testaccuracy10p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloss10pLISTglobal = list(map(lambda x: x['global'], testloss10pLIST))\n",
    "testaccuracy10pLISTglobal = list(map(lambda x: x['global'], testaccuracy10pLIST))\n",
    "\n",
    "trainloss10pMEAN = np.sum(np.array(trainloss10pLIST), axis=0) / len(trainloss10pLIST)\n",
    "testloss10pMEAN = {\"global\": np.sum(np.array(testloss10pLISTglobal), axis=0) / len(testloss10pLISTglobal)}\n",
    "testaccuracy10pMEAN = {\"global\": np.sum(np.array(testaccuracy10pLISTglobal), axis=0) / len(testaccuracy10pLISTglobal)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train and test loss\n",
    "plt.plot(trainloss10pMEAN, label='10% Train Loss')\n",
    "plt.plot(testloss10pMEAN['global'], label='10% Test Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot test accuracy\n",
    "plt.plot(testaccuracy10pMEAN['global'], label='Global Test Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.grid()\n",
    "\n",
    "# Set y-axis limits\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a confusion matrix for the test set\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, title='Confusion Matrix', labels=None):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Known to be true')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for segmentation in splitSegmentations:\n",
    "    X_test_total_tensor = torch.tensor(segmentation['X_test_total'], dtype=torch.float32)\n",
    "    plot_confusion_matrix(segmentation['y_test_total'], net(X_test_total_tensor) >= 0.5, title='10% Test Set Confusion Matrix', labels=[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a network for each segmentation, and take the mean of the metrics\n",
    "trainloss50pLIST = []\n",
    "testloss50pLIST = []\n",
    "testaccuracy50pLIST = []\n",
    "for segmentation in dataloaderSegmentations:\n",
    "    net = Net()\n",
    "\n",
    "    trainloss50p, testloss50p, testaccuracy50p = trainAndEvaluateNetwork(net, epochs, segmentation['train_50p'], {\"global\": segmentation['test']}, lr, device)\n",
    "    trainloss50pLIST.append(trainloss50p)\n",
    "    testloss50pLIST.append(testloss50p)\n",
    "    testaccuracy50pLIST.append(testaccuracy50p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloss50pLISTglobal = list(map(lambda x: x['global'], testloss50pLIST))\n",
    "testaccuracy50pLISTglobal = list(map(lambda x: x['global'], testaccuracy50pLIST))\n",
    "\n",
    "trainloss50pMEAN = np.sum(np.array(trainloss50pLIST), axis=0) / len(trainloss50pLIST)\n",
    "testloss50pMEAN = {\"global\": np.sum(np.array(testloss50pLISTglobal), axis=0) / len(testloss50pLISTglobal)}\n",
    "testaccuracy50pMEAN = {\"global\": np.sum(np.array(testaccuracy50pLISTglobal), axis=0) / len(testaccuracy50pLISTglobal)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train loss\n",
    "plt.plot(trainloss50pMEAN, label='50% Train Loss')\n",
    "plt.plot(testloss50pMEAN['global'], label='50% Test Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot test accuracy\n",
    "plt.plot(testaccuracy50pMEAN['global'], label='50% Test Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid()\n",
    "\n",
    "# Set y-axis limits\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_total_tensor = torch.tensor(splitSegmentations['X_test_total'], dtype=torch.float32)\n",
    "plot_confusion_matrix(splitSegmentations['y_test_total'], net(X_test_total_tensor) >= 0.5, title='50% Test Set Confusion Matrix', labels=[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a network for each segmentation, and take the mean of the metrics\n",
    "trainloss100pLIST = []\n",
    "testloss100pLIST = []\n",
    "testaccuracy100pLIST = []\n",
    "for segmentation in dataloaderSegmentations:\n",
    "    net = Net()\n",
    "\n",
    "    trainloss100p, testloss100p, testaccuracy100p = trainAndEvaluateNetwork(net, epochs, segmentation['train_100p'], {\"global\": segmentation['test']}, lr, device)\n",
    "    trainloss100pLIST.append(trainloss100p)\n",
    "    testloss100pLIST.append(testloss100p)\n",
    "    testaccuracy100pLIST.append(testaccuracy100p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloss100pLISTglobal = list(map(lambda x: x['global'], testloss100pLIST))\n",
    "testaccuracy100pLISTglobal = list(map(lambda x: x['global'], testaccuracy100pLIST))\n",
    "\n",
    "trainloss100pMEAN = np.sum(np.array(trainloss100pLIST), axis=0) / len(trainloss100pLIST)\n",
    "testloss100pMEAN = {\"global\": np.sum(np.array(testloss100pLISTglobal), axis=0) / len(testloss100pLISTglobal)}\n",
    "testaccuracy100pMEAN = {\"global\": np.sum(np.array(testaccuracy100pLISTglobal), axis=0) / len(testaccuracy100pLISTglobal)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train loss\n",
    "plt.plot(trainloss100pMEAN, label='100% Train Loss')\n",
    "plt.plot(testloss100pMEAN['global'], label='100% Test Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "\n",
    "print(f\"{testloss100pMEAN['global'][-1]=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot test accuracy\n",
    "plt.plot(testaccuracy100pMEAN['global'], label='100% Test Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid()\n",
    "\n",
    "# Set y-axis limits\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_total_tensor = torch.tensor(splitSegmentations['X_test_total'], dtype=torch.float32)\n",
    "plot_confusion_matrix(splitSegmentations['X_test_total'], net(X_test_total_tensor) >= 0.5, title='100% Test Set Confusion Matrix', labels=[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Accuracies plotted together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot test accuracy\n",
    "plt.plot(testaccuracy100pMEAN['global'], label='100% Test Accuracy')\n",
    "plt.plot(testaccuracy50pMEAN['global'], label='50% Test Accuracy')\n",
    "plt.plot(testaccuracy10pMEAN['global'], label='10% Test Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid()\n",
    "\n",
    "# Set y-axis limits\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{testaccuracy100pMEAN['global'][-1]=}\")\n",
    "print(f\"{testaccuracy50pMEAN['global'][-1]=}\")\n",
    "print(f\"{testaccuracy10pMEAN['global'][-1]=}\")\n",
    "print(f\"{np.max(testaccuracy100pMEAN['global'])=}\")\n",
    "print(f\"{np.max(testaccuracy50pMEAN['global'])=}\")\n",
    "print(f\"{np.max(testaccuracy10pMEAN['global'])=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
